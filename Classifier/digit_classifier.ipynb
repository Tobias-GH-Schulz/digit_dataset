{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:21:19.207277Z",
     "start_time": "2021-03-22T12:21:19.200825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from digit_train_dataset import digit_train_dataset\n",
    "from digit_test_dataset import digit_test_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:09:57.076969Z",
     "start_time": "2021-03-22T09:09:57.074664Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:09:57.118940Z",
     "start_time": "2021-03-22T09:09:57.079111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Load Data\n",
    "train_dataset = ImageFolder(root = './dataset_images_keras/train',\n",
    "                             transform = train_transforms)\n",
    "test_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:09:59.204608Z",
     "start_time": "2021-03-22T09:09:59.048505Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(image, label, dataset):\n",
    "    print(f\"Label: {label}\") \n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    plt.show()\n",
    "\n",
    "show_image(*train_dataset[10], train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:10:14.082667Z",
     "start_time": "2021-03-22T09:10:14.079527Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path, epoch, model_name):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    #print(f_path)\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, model_name + \"_epoch_\" + str(epoch) + \"_model.pt\")\n",
    "    \n",
    "    # if it is a best model, min validation loss\n",
    "    #if is_best:\n",
    "    #    best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "    #    shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:10:17.249254Z",
     "start_time": "2021-03-22T09:10:17.247012Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_checkpoints/resnet/\"\n",
    "best_model_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_best_model/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:11:04.906890Z",
     "start_time": "2021-03-22T09:11:04.896953Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, valid_loss_min_input, checkpoint_path, best_model_path, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Keyword arguments:\n",
    "    start_epochs -- the real part (default 0.0)\n",
    "    n_epochs -- the imaginary part (default 0.0)\n",
    "    valid_loss_min_input\n",
    "    loaders\n",
    "    model\n",
    "    optimizer\n",
    "    criterion\n",
    "    use_cuda\n",
    "    checkpoint_path\n",
    "    best_model_path\n",
    "    \n",
    "    returns trained model\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = valid_loss_min_input \n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    train_losses, valid_losses = [], []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    print(model_name)\n",
    "    \n",
    "    for epoch in range(start_epochs, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, targets)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            ## record the average training loss, using something like\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            # move to GPU\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            ## update the average validation loss\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(x)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            _, predictions = output.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(test_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "              \n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "    \n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    \n",
    "    documentation[model_name] = float(num_correct)/float(num_samples)*100\n",
    "    \n",
    "    # return trained model\n",
    "    return model, train_losses, valid_losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T20:51:07.118469Z",
     "start_time": "2021-03-18T20:51:06.927337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T20:51:37.136563Z",
     "start_time": "2021-03-18T20:51:37.127573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:11:30.822992Z",
     "start_time": "2021-03-22T09:11:30.537942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T09:11:45.215986Z",
     "start_time": "2021-03-22T09:11:45.209560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(512, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:11:59.405199Z",
     "start_time": "2021-03-22T09:11:48.144690Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      "Epoch: 0 \tTraining Loss: 0.000090 \tValidation Loss: 0.000176\n",
      "Validation loss decreased (0.005000 --> 0.000176).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.000042 \tValidation Loss: 0.000161\n",
      "Validation loss decreased (0.000176 --> 0.000161).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000030 \tValidation Loss: 0.000129\n",
      "Validation loss decreased (0.000161 --> 0.000129).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000029 \tValidation Loss: 0.000126\n",
      "Validation loss decreased (0.000129 --> 0.000126).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000023 \tValidation Loss: 0.000133\n",
      "Epoch: 5 \tTraining Loss: 0.000023 \tValidation Loss: 0.000092\n",
      "Validation loss decreased (0.000126 --> 0.000092).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000023 \tValidation Loss: 0.000095\n",
      "Epoch: 7 \tTraining Loss: 0.000018 \tValidation Loss: 0.000122\n",
      "Epoch: 8 \tTraining Loss: 0.000018 \tValidation Loss: 0.000083\n",
      "Validation loss decreased (0.000092 --> 0.000083).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.000014 \tValidation Loss: 0.000099\n",
      "Epoch: 10 \tTraining Loss: 0.000015 \tValidation Loss: 0.000092\n",
      "Epoch: 11 \tTraining Loss: 0.000015 \tValidation Loss: 0.000108\n",
      "Epoch: 12 \tTraining Loss: 0.000013 \tValidation Loss: 0.000082\n",
      "Validation loss decreased (0.000083 --> 0.000082).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.000012 \tValidation Loss: 0.000071\n",
      "Validation loss decreased (0.000082 --> 0.000071).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 0.000013 \tValidation Loss: 0.000095\n",
      "Epoch: 15 \tTraining Loss: 0.000010 \tValidation Loss: 0.000087\n",
      "Epoch: 16 \tTraining Loss: 0.000009 \tValidation Loss: 0.000068\n",
      "Validation loss decreased (0.000071 --> 0.000068).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.000009 \tValidation Loss: 0.000085\n",
      "Epoch: 18 \tTraining Loss: 0.000012 \tValidation Loss: 0.000106\n",
      "Epoch: 19 \tTraining Loss: 0.000008 \tValidation Loss: 0.000080\n",
      "Epoch: 20 \tTraining Loss: 0.000011 \tValidation Loss: 0.000109\n",
      "Got 29857 / 31500 with accuracy 94.78\n"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:45.481911Z",
     "start_time": "2021-03-20T13:28:43.741079Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inception \n",
    "model = torchvision.models.inception_v3(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:15.009855Z",
     "start_time": "2021-03-20T13:28:14.997719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:17.820682Z",
     "start_time": "2021-03-20T13:28:17.674981Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:52:31.584889Z",
     "start_time": "2021-03-20T16:52:31.529118Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AlexNet\n",
    "model = torchvision.models.squeezenet1_0(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:52:36.200887Z",
     "start_time": "2021-03-20T16:52:36.193873Z"
    }
   },
   "outputs": [],
   "source": [
    "# SqueezeNet\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('flat', nn.Flatten()),\n",
    "                          ('fc1', nn.Linear(512, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:57:13.079745Z",
     "start_time": "2021-03-20T16:52:41.450021Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet\n",
      "Epoch: 0 \tTraining Loss: 0.000079 \tValidation Loss: 0.000191\n",
      "Validation loss decreased (0.005000 --> 0.000191).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.000037 \tValidation Loss: 0.000145\n",
      "Validation loss decreased (0.000191 --> 0.000145).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000028 \tValidation Loss: 0.000164\n",
      "Epoch: 3 \tTraining Loss: 0.000024 \tValidation Loss: 0.000125\n",
      "Validation loss decreased (0.000145 --> 0.000125).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000021 \tValidation Loss: 0.000117\n",
      "Validation loss decreased (0.000125 --> 0.000117).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000019 \tValidation Loss: 0.000113\n",
      "Validation loss decreased (0.000117 --> 0.000113).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000018 \tValidation Loss: 0.000136\n",
      "Epoch: 7 \tTraining Loss: 0.000017 \tValidation Loss: 0.000112\n",
      "Validation loss decreased (0.000113 --> 0.000112).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000016 \tValidation Loss: 0.000146\n",
      "Epoch: 9 \tTraining Loss: 0.000013 \tValidation Loss: 0.000125\n",
      "Epoch: 10 \tTraining Loss: 0.000016 \tValidation Loss: 0.000276\n",
      "Epoch: 11 \tTraining Loss: 0.000016 \tValidation Loss: 0.000110\n",
      "Validation loss decreased (0.000112 --> 0.000110).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.000012 \tValidation Loss: 0.000093\n",
      "Validation loss decreased (0.000110 --> 0.000093).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.000010 \tValidation Loss: 0.000109\n",
      "Epoch: 14 \tTraining Loss: 0.000009 \tValidation Loss: 0.000139\n",
      "Epoch: 15 \tTraining Loss: 0.000010 \tValidation Loss: 0.000094\n",
      "Epoch: 16 \tTraining Loss: 0.000010 \tValidation Loss: 0.000152\n",
      "Epoch: 17 \tTraining Loss: 0.000013 \tValidation Loss: 0.000103\n",
      "Epoch: 18 \tTraining Loss: 0.000010 \tValidation Loss: 0.000092\n",
      "Validation loss decreased (0.000093 --> 0.000092).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.000007 \tValidation Loss: 0.000113\n",
      "Epoch: 20 \tTraining Loss: 0.000009 \tValidation Loss: 0.000116\n",
      "Got 29477 / 31500 with accuracy 93.58\n"
     ]
    }
   ],
   "source": [
    "# SqueezeNet \n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:00:46.938554Z",
     "start_time": "2021-03-20T17:00:46.934751Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"documentation.json\", \"w\") as outfile: \n",
    "    json.dump(documentation, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T21:40:16.073675Z",
     "start_time": "2021-03-18T21:40:16.071237Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"sample_file.json\", \"r+\") as file:\n",
    "    data = json.load(file)\n",
    "    data.update(documentation)\n",
    "    file.seek(0)\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:17:34.476440Z",
     "start_time": "2021-03-22T12:17:34.470739Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:17:38.409326Z",
     "start_time": "2021-03-22T12:17:38.402518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (fc1): Linear(in_features=512, out_features=500, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "    (output): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:25:39.015592Z",
     "start_time": "2021-03-22T12:25:39.012119Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = prediction_transforms(image).float()\n",
    "    print(image_tensor.shape)\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:19:50.693270Z",
     "start_time": "2021-03-20T17:19:50.570848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f985dd6e8d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img67 = cv2.imread(\"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/67.png\")\n",
    "plt.imshow(img67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:23:40.736767Z",
     "start_time": "2021-03-20T17:23:40.719678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = predict_image(img67)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:17:46.396034Z",
     "start_time": "2021-03-22T12:17:46.387383Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/\"\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "images = [ x for x in images if \".DS_Store\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T12:25:42.971140Z",
     "start_time": "2021-03-22T12:25:42.945899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 22)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b6f51c1db2bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-3169b9e72777>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv_clone/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv_clone/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv_clone/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for image in images:\n",
    "    image_name = image.split(\"/\")[-1:][0].split('.')[0]\n",
    "    img = Image.open (image)\n",
    "    print(img.size)\n",
    "    label = predict_image(img)\n",
    "    predictions[image_name] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:37:01.879456Z",
     "start_time": "2021-03-20T17:37:01.875626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'77': 8,\n",
       " '62': 8,\n",
       " '61': 5,\n",
       " '72': 6,\n",
       " '67': 4,\n",
       " '14': 9,\n",
       " '28': 8,\n",
       " '15': 9,\n",
       " '13': 1,\n",
       " '10': 8,\n",
       " '21': 8,\n",
       " '20': 9,\n",
       " '36': 8,\n",
       " '37': 4,\n",
       " '32': 9,\n",
       " '26': 9,\n",
       " '81': 9,\n",
       " '56': 8,\n",
       " '42': 8,\n",
       " '5': 7,\n",
       " '80': 7,\n",
       " '69': 6,\n",
       " '68': 1,\n",
       " '54': 9,\n",
       " '40': 8,\n",
       " '2': 8,\n",
       " '50': 2,\n",
       " '45': 1,\n",
       " '1': 3,\n",
       " '46': 7}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
