{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:23:35.932864Z",
     "start_time": "2021-03-20T17:23:35.926437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from digit_train_dataset import digit_train_dataset\n",
    "from digit_test_dataset import digit_test_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:07:56.951302Z",
     "start_time": "2021-03-20T13:07:56.948896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:30:58.299027Z",
     "start_time": "2021-03-20T13:30:58.230791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_dataset = ImageFolder(root = './dataset_images_keras/train',\n",
    "                             transform = train_transforms)\n",
    "test_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:31:05.941379Z",
     "start_time": "2021-03-20T13:31:05.832295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(image, label, dataset):\n",
    "    print(f\"Label: {label}\") \n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    plt.show()\n",
    "\n",
    "show_image(*train_dataset[10], train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:07:57.132793Z",
     "start_time": "2021-03-20T13:07:57.130113Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path, epoch, model_name):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    #print(f_path)\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, model_name + \"_epoch_\" + str(epoch) + \"_model.pt\")\n",
    "    \n",
    "    # if it is a best model, min validation loss\n",
    "    #if is_best:\n",
    "    #    best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "    #    shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:07:57.136747Z",
     "start_time": "2021-03-20T13:07:57.134512Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_checkpoints/resnet/\"\n",
    "best_model_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_best_model/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:09:38.663266Z",
     "start_time": "2021-03-20T17:09:38.652332Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, valid_loss_min_input, checkpoint_path, best_model_path, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Keyword arguments:\n",
    "    start_epochs -- the real part (default 0.0)\n",
    "    n_epochs -- the imaginary part (default 0.0)\n",
    "    valid_loss_min_input\n",
    "    loaders\n",
    "    model\n",
    "    optimizer\n",
    "    criterion\n",
    "    use_cuda\n",
    "    checkpoint_path\n",
    "    best_model_path\n",
    "    \n",
    "    returns trained model\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = valid_loss_min_input \n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    train_losses, valid_losses = [], []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    print(model_name)\n",
    "    \n",
    "    for epoch in range(start_epochs, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, targets)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            ## record the average training loss, using something like\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            # move to GPU\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            ## update the average validation loss\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(x)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            _, predictions = output.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(test_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "              \n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "    \n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    \n",
    "    documentation[model_name] = float(num_correct)/float(num_samples)*100\n",
    "    \n",
    "    # return trained model\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T20:51:07.118469Z",
     "start_time": "2021-03-18T20:51:06.927337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T20:51:37.136563Z",
     "start_time": "2021-03-18T20:51:37.127573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T14:15:59.294209Z",
     "start_time": "2021-03-20T14:15:59.018307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resnet18\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T14:16:06.978288Z",
     "start_time": "2021-03-20T14:16:06.971659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(512, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T14:27:26.332898Z",
     "start_time": "2021-03-20T14:16:10.564347Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      "Epoch: 0 \tTraining Loss: 0.000174 \tValidation Loss: 0.000585\n",
      "Validation loss decreased (0.005000 --> 0.000585).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.000128 \tValidation Loss: 0.000529\n",
      "Validation loss decreased (0.000585 --> 0.000529).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000121 \tValidation Loss: 0.000528\n",
      "Validation loss decreased (0.000529 --> 0.000528).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000111 \tValidation Loss: 0.000462\n",
      "Validation loss decreased (0.000528 --> 0.000462).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000104 \tValidation Loss: 0.000439\n",
      "Validation loss decreased (0.000462 --> 0.000439).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000098 \tValidation Loss: 0.000418\n",
      "Validation loss decreased (0.000439 --> 0.000418).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000095 \tValidation Loss: 0.000408\n",
      "Validation loss decreased (0.000418 --> 0.000408).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000090 \tValidation Loss: 0.000385\n",
      "Validation loss decreased (0.000408 --> 0.000385).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000086 \tValidation Loss: 0.000383\n",
      "Validation loss decreased (0.000385 --> 0.000383).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.000083 \tValidation Loss: 0.000381\n",
      "Validation loss decreased (0.000383 --> 0.000381).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.000080 \tValidation Loss: 0.000361\n",
      "Validation loss decreased (0.000381 --> 0.000361).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 0.000079 \tValidation Loss: 0.000375\n",
      "Epoch: 12 \tTraining Loss: 0.000080 \tValidation Loss: 0.000390\n",
      "Epoch: 13 \tTraining Loss: 0.000075 \tValidation Loss: 0.000406\n",
      "Epoch: 14 \tTraining Loss: 0.000074 \tValidation Loss: 0.000352\n",
      "Validation loss decreased (0.000361 --> 0.000352).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.000074 \tValidation Loss: 0.000378\n",
      "Epoch: 16 \tTraining Loss: 0.000068 \tValidation Loss: 0.000356\n",
      "Epoch: 17 \tTraining Loss: 0.000068 \tValidation Loss: 0.000365\n",
      "Epoch: 18 \tTraining Loss: 0.000067 \tValidation Loss: 0.000328\n",
      "Validation loss decreased (0.000352 --> 0.000328).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.000070 \tValidation Loss: 0.000332\n",
      "Epoch: 20 \tTraining Loss: 0.000066 \tValidation Loss: 0.000340\n",
      "Got 25010 / 31500 with accuracy 79.40\n"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:45.481911Z",
     "start_time": "2021-03-20T13:28:43.741079Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inception \n",
    "model = torchvision.models.inception_v3(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:15.009855Z",
     "start_time": "2021-03-20T13:28:14.997719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(2048, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.fc = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T13:28:17.820682Z",
     "start_time": "2021-03-20T13:28:17.674981Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inception\n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:52:31.584889Z",
     "start_time": "2021-03-20T16:52:31.529118Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AlexNet\n",
    "model = torchvision.models.squeezenet1_0(pretrained=True)\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:52:36.200887Z",
     "start_time": "2021-03-20T16:52:36.193873Z"
    }
   },
   "outputs": [],
   "source": [
    "# SqueezeNet\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "from collections import OrderedDict\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('flat', nn.Flatten()),\n",
    "                          ('fc1', nn.Linear(512, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 10)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "    \n",
    "model.classifier = classifier\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T16:57:13.079745Z",
     "start_time": "2021-03-20T16:52:41.450021Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet\n",
      "Epoch: 0 \tTraining Loss: 0.000079 \tValidation Loss: 0.000191\n",
      "Validation loss decreased (0.005000 --> 0.000191).  Saving model ...\n",
      "Epoch: 1 \tTraining Loss: 0.000037 \tValidation Loss: 0.000145\n",
      "Validation loss decreased (0.000191 --> 0.000145).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000028 \tValidation Loss: 0.000164\n",
      "Epoch: 3 \tTraining Loss: 0.000024 \tValidation Loss: 0.000125\n",
      "Validation loss decreased (0.000145 --> 0.000125).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000021 \tValidation Loss: 0.000117\n",
      "Validation loss decreased (0.000125 --> 0.000117).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000019 \tValidation Loss: 0.000113\n",
      "Validation loss decreased (0.000117 --> 0.000113).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000018 \tValidation Loss: 0.000136\n",
      "Epoch: 7 \tTraining Loss: 0.000017 \tValidation Loss: 0.000112\n",
      "Validation loss decreased (0.000113 --> 0.000112).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000016 \tValidation Loss: 0.000146\n",
      "Epoch: 9 \tTraining Loss: 0.000013 \tValidation Loss: 0.000125\n",
      "Epoch: 10 \tTraining Loss: 0.000016 \tValidation Loss: 0.000276\n",
      "Epoch: 11 \tTraining Loss: 0.000016 \tValidation Loss: 0.000110\n",
      "Validation loss decreased (0.000112 --> 0.000110).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.000012 \tValidation Loss: 0.000093\n",
      "Validation loss decreased (0.000110 --> 0.000093).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.000010 \tValidation Loss: 0.000109\n",
      "Epoch: 14 \tTraining Loss: 0.000009 \tValidation Loss: 0.000139\n",
      "Epoch: 15 \tTraining Loss: 0.000010 \tValidation Loss: 0.000094\n",
      "Epoch: 16 \tTraining Loss: 0.000010 \tValidation Loss: 0.000152\n",
      "Epoch: 17 \tTraining Loss: 0.000013 \tValidation Loss: 0.000103\n",
      "Epoch: 18 \tTraining Loss: 0.000010 \tValidation Loss: 0.000092\n",
      "Validation loss decreased (0.000093 --> 0.000092).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.000007 \tValidation Loss: 0.000113\n",
      "Epoch: 20 \tTraining Loss: 0.000009 \tValidation Loss: 0.000116\n",
      "Got 29477 / 31500 with accuracy 93.58\n"
     ]
    }
   ],
   "source": [
    "# SqueezeNet \n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:00:46.938554Z",
     "start_time": "2021-03-20T17:00:46.934751Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"documentation.json\", \"w\") as outfile: \n",
    "    json.dump(documentation, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T21:40:16.073675Z",
     "start_time": "2021-03-18T21:40:16.071237Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"sample_file.json\", \"r+\") as file:\n",
    "    data = json.load(file)\n",
    "    data.update(documentation)\n",
    "    file.seek(0)\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:14:07.197957Z",
     "start_time": "2021-03-20T17:14:07.195501Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:18:47.325150Z",
     "start_time": "2021-03-20T17:18:47.320444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (flat): Flatten()\n",
       "    (fc1): Linear(in_features=512, out_features=500, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       "    (output): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:16:20.575174Z",
     "start_time": "2021-03-20T17:16:20.571273Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:19:50.693270Z",
     "start_time": "2021-03-20T17:19:50.570848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f985dd6e8d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOaUlEQVR4nO3df+hdd33H8edr0f6xWmmrtPZHnJ2EsigjSsmUOqnbLGkoqw43EsbsnFAVCwr+YaegMhAGQ52yUokzWEFbB1tnmFEbiqwK/qgt6S/b2lji+jUhQWXVotDFvvfHPZHv59t7k5t77s33fL95PuBw7znnc+45h2/uK+fX/bxTVUjScb+z2hsgaVgMBUkNQ0FSw1CQ1DAUJDWet9obME4Sb4lIC1ZVGTfdIwVJjV6hkGRbkseSHEhy05j5SfKpbv4DSV7dZ32SFm/mUEiyAbgZuAbYDOxMsnlFs2uATd1wA3DLrOuTdHr0OVLYChyoqieq6hngduC6FW2uAz5fI98Bzk1yUY91SlqwPqFwCfDksvGlbtqptgEgyQ1Jvp/k+z22SVJPfe4+jLtyufKuwTRtRhOrdgG7wLsP0mrqc6SwBGxcNn4pcGiGNpIGpE8o3ANsSnJZkrOAHcCeFW32AG/t7kK8Bniqqg73WKekBZv59KGqjiW5Efg6sAHYXVUPJ3lnN//TwF5gO3AA+BXwtv6bLGmRMsT+FLymIC2eTzRKmoqhIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGn3qPmxM8o0kjyR5OMl7xrS5KslTSfZ3w4f6ba6kRevTm/Mx4H1VdV+Sc4B7k+yrqh+saPfNqrq2x3oknUYzHylU1eGquq97/0vgESbUdJC0dszlmkKSlwGvAr47ZvZrk9yf5KtJXnGCz7AYjDQAvTtuTfIC4L+Bj1bVf6yY90Lg2ap6Osl24JNVtWmKz7TjVmnBJnXc2isUkjwf+C/g61X18SnaHwSuqKqfnqSdoSAt2Nx7c04S4LPAI5MCIclLunYk2dqt72ezrlPS4vW5+3Al8DfAg0n2d9M+ALwUflsM5i3Au5IcA34N7KghFpqQ9FsWg5HOUBaDkTQVQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDV6hUKSg0ke7Aq9PKcX5ox8KsmBJA8keXWf9UlavD7dsR33hhN0xHoNsKkb/gi4pXuVNFCLPn24Dvh8jXwHODfJRQtep6Qe+oZCAXcmuTfJDWPmXwI8uWx8iQlVpCwGIw1D39OHK6vqUJILgH1JHq2qu5fNH9cx5NhOWatqF7AL7LhVWk29jhSq6lD3ehS4A9i6oskSsHHZ+KXAoT7rlLRYfYrBnN1VmybJ2cDVwEMrmu0B3trdhXgN8FRVHZ55ayUtXJ/ThwuBO7oCUM8DvlhVX0vyTvhtMZi9wHbgAPAr4G39NldnimnrkXT//jRHFoPRIBkKi2cxGElTMRQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVJjHv0pSFMb4sNyanmkIKlhKEhqGAqSGoaCpIahIKlhKEhq9Ol56fKu3sPx4RdJ3ruizVVJnlrW5kO9t1jSQs38nEJVPQZsAUiyAfgJo34aV/pmVV0763oknV7zOn34U+BHVfXjOX2epFUyr1DYAdw2Yd5rk9yf5KtJXjHpA6z7sLZV1VSDhq93H41JzmLUbfsrqurIinkvBJ6tqqeTbAc+WVWbpvhM//WsMav1hbePxtktso/Ga4D7VgZCt9JfVNXT3fu9wPOTvHgO65S0IPMIhZ1MOHVI8pJ0UZ5ka7e+n81hnZIWpNevJJP8LvBG4B3Lpi2v+/AW4F1JjgG/BnaUJ5bSoFn3QXPhNYW1x7oPkqZiKEhqGAqSGoaCpIZ9NOqE5n0BcdoLg0O8AH6m8EhBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsMnGjUX/oR5/fBIQVLjpKGQZHeSo0keWjbt/CT7kjzevZ43YdltSR5LciDJTfPccEmLMc2RwueAbSum3QTc1fXMfFc33ugKxNzMqGPXzcDOJJt7ba2khTtpKFTV3cDPV0y+Dri1e38r8KYxi24FDlTVE1X1DHB7t5ykAZv1msKFVXUYoHu9YEybS4Anl40vddPGshiMNAyLvPsw7nL0xB/JV9UuYBfYcau0mmY9UjiS5CKA7vXomDZLwMZl45cyqiQlacBmDYU9wPXd++uBL49pcw+wKcllXWm5Hd1ykoZsioKgtwGHgf9j9L//24EXMbrr8Hj3en7X9mJg77JltwM/BH4EfPAUipCWwzCGaa2X9Z5Jw6Tvn8VgzlCr1ffitKbdPp+knJ3FYCRNxVCQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSwz4adUI+MXjm8UhBUsNQkNQwFCQ1DAVJDUNBUsNQkNSYtRjMPyV5NMkDSe5Icu6EZQ8meTDJfntpltaGWYvB7ANeWVV/yKi7tb8/wfJvqKotVXXFbJso6XSaqRhMVd1ZVce60e8w6qlZ0jowj2sKfwd8dcK8Au5Mcm+SG070IRaDmY9T6Bx3XTjT9vd06PWYc5IPAseAL0xocmVVHUpyAbAvyaPdkcdzlMVgpEGY+UghyfXAtcBf14QorqpD3etR4A5G9SUlDdhMoZBkG/B+4M+r6lcT2pyd5Jzj74GrgYfGtZU0HNPckrwN+DZweZKlJG8H/gU4h9Epwf4kn+7aXpxkb7fohcC3ktwPfA/4SlV9bSF7IWluLAazzgy9yMu01st+DJnFYCRNxVCQ1DAUJDUMBUkN+2jUCQ3xQvQsrGI9PY8UJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDV8onGdWS9P5PnT6dUza92HjyT5SdfByv4k2ycsuy3JY0kOJLlpnhsuaTFmrfsA8ImunsOWqtq7cmaSDcDNwDXAZmBnks19NlbS4s1U92FKW4EDVfVEVT0D3A5cN8PnSDqN+lxovLErG7c7yXlj5l8CPLlsfKmbJmnAZg2FW4CXA1uAw8DHxrQZd2Vn4tUji8FIwzBTKFTVkar6TVU9C3yG8fUcloCNy8YvBQ6d4DN3VdUV1pyUVtesdR8uWjb6ZsbXc7gH2JTksiRnATuAPbOsT9Lpc9LnFLq6D1cBL06yBHwYuCrJFkanAweBd3RtLwb+taq2V9WxJDcCXwc2ALur6uFF7ISk+bHugwbJh5cWb1LdB59o1Jrml33+/O2DpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqTNPz0m7gWuBoVb2ym/Yl4PKuybnA/1bVljHLHgR+CfwGOGb/i9LwnbTnpSSvB54GPn88FFbM/xjwVFX9w5h5B4Erquqnp7RR9rx0xpu25yU7WZndzD0vVdXdSV42bl5Gf5G/Av6k19ZJGoy+1xT+GDhSVY9PmF/AnUnuTXLDiT7Iug9aLslUg+avbx+NO4HbTjD/yqo6lOQCYF+SR7sydM9RVbuAXeDpg7SaZj5SSPI84C+AL01qU1WHutejwB2MLxojaUD6nD78GfBoVS2Nm5nk7CTnHH8PXM34ojGSBuSkodAVg/k2cHmSpSRv72btYMWpQ5KLkxwvS38h8K0k9wPfA75SVV+b36ZLWgSLwUhnqEm3JH2iUVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSY1pel7amOQbSR5J8nCS93TTz0+yL8nj3et5E5bfluSxJAeS3DTvHZA0X9MUg7kIuKiq7uv6XLwXeBPwt8DPq+ofuy/7eVX1/hXLbgB+CLwRWALuAXZW1Q9Osk57XpIWbOael6rqcFXd173/JfAIcAlwHXBr1+xWRkGx0lbgQFU9UVXPALd3y0kaqFO6ptBVinoV8F3gwqo6DKPgAC4Ys8glwJPLxpe6aeM+22Iw0gBMXQwmyQuAfwfeW1W/mLI6z7hGY08NLAYjDcNURwpJns8oEL5QVf/RTT7SXW84ft3h6JhFl4CNy8YvBQ7NvrmSFm2auw8BPgs8UlUfXzZrD3B99/564MtjFr8H2JTksiRnMaoVsaffJktaqKo64QC8jtEh/wPA/m7YDrwIuAt4vHs9v2t/MbB32fLbGd2B+BHwwZOtr1umHBwcFjtM+v5ZDEY6Q1kMRtJUDAVJDUNBUsNQkNQwFCQ1DAVJDUNBUsNQkNQwFCQ1pv6V5Gn2U+DHK6a9uJu+lrkPw7Ee9qPPPvzepBmDfMx5nCTfr6orVns7+nAfhmM97Mei9sHTB0kNQ0FSYy2Fwq7V3oA5cB+GYz3sx0L2Yc1cU5B0eqylIwVJp4GhIKkx+FBYLxWmkhxM8mCS/WulG/sku5McTfLQsmlTVQYbkgn78ZEkP+n+HvuTbF/NbTyZvpXaTsWgQ6GrMHUzcA2wGdiZZPPqblUvb6iqLWvo/vjngG0rpt0E3FVVmxj1zbkWgvpzPHc/AD7R/T22VNXe07xNp+oY8L6q+gPgNcC7u+/C3P8egw4FrDC1qqrqbuDnKyZfx8krgw3KhP1YU3pWajslQw+FqStMrQEF3Jnk3iQ3rPbG9DBNZbC14sYkD3SnF4M/DTpuhkptp2TooTB1hak14MqqejWjU6F3J3n9am/QGe4W4OXAFuAw8LFV3ZoprazUtoh1DD0U1k2Fqao61L0eBe5gdGq0Fk1TGWzwqupIVf2mqp4FPsMa+Hv0qNR2SoYeCuuiwlSSs5Occ/w9cDXw0ImXGqxpKoMN3vEvUufNDPzv0bNS26mta+hPNHa3iv4Z2ADsrqqPru4Wnbokv8/o6ABGP1f/4lrYjyS3AVcx+onuEeDDwH8C/wa8FPgf4C+ratAX8Sbsx1WMTh0KOAi84/i5+RAleR3wTeBB4Nlu8gcYXVeY699j8KEg6fQa+umDpNPMUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNf4fQltrLFHfjSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img67 = cv2.imread(\"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/67.png\")\n",
    "plt.imshow(img67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:23:40.736767Z",
     "start_time": "2021-03-20T17:23:40.719678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = predict_image(img67)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:29:26.222647Z",
     "start_time": "2021-03-20T17:29:26.218373Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/\"\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "images = [ x for x in images if \".DS_Store\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:36:59.386325Z",
     "start_time": "2021-03-20T17:36:59.269973Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for image in images:\n",
    "    image_name = image.split(\"/\")[-1:][0].split('.')[0]\n",
    "    img = cv2.imread(image)\n",
    "    label = predict_image(img)\n",
    "    predictions[image_name] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T17:37:01.879456Z",
     "start_time": "2021-03-20T17:37:01.875626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'77': 8,\n",
       " '62': 8,\n",
       " '61': 5,\n",
       " '72': 6,\n",
       " '67': 4,\n",
       " '14': 9,\n",
       " '28': 8,\n",
       " '15': 9,\n",
       " '13': 1,\n",
       " '10': 8,\n",
       " '21': 8,\n",
       " '20': 9,\n",
       " '36': 8,\n",
       " '37': 4,\n",
       " '32': 9,\n",
       " '26': 9,\n",
       " '81': 9,\n",
       " '56': 8,\n",
       " '42': 8,\n",
       " '5': 7,\n",
       " '80': 7,\n",
       " '69': 6,\n",
       " '68': 1,\n",
       " '54': 9,\n",
       " '40': 8,\n",
       " '2': 8,\n",
       " '50': 2,\n",
       " '45': 1,\n",
       " '1': 3,\n",
       " '46': 7}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
