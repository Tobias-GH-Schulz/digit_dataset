{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:42.938905Z",
     "start_time": "2021-03-21T13:02:42.932508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision.transforms as transforms \n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "from digit_train_dataset import digit_train_dataset\n",
    "from digit_test_dataset import digit_test_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:42.943450Z",
     "start_time": "2021-03-21T13:02:42.941100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:42.980143Z",
     "start_time": "2021-03-21T13:02:42.945754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "# Load Data\n",
    "train_dataset = ImageFolder(root = './dataset_images_keras/train',\n",
    "                             transform = train_transforms)\n",
    "test_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.086831Z",
     "start_time": "2021-03-21T13:02:42.982403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQYklEQVR4nO3dYYxVdXrH8d8jMIADRlExiAJ2g1DUCNVgDWjUTTfqG/DF1uVFQ6nJ7Is1WZMmrdm+WJOmiWm7bfqibjLbNWCz1RjRrCFkd4nZ1GrixkFHZDrUQbTuCA5SQxgEGZh5+mIOm1md8/zHe+6958L/+0kmM3OfOff+5zI/zrn3Of/zN3cXgIvfJXUPAEB7EHYgE4QdyARhBzJB2IFMzG7ng5kZb/23gJmV1jq52xKNW2rt2Ot87FZz92l/uUphN7P7Jf2LpFmS/s3dn6xyfxerWbNmhfXx8fGwPnt2/M8U3f+ZM2fCbVOqhiLavqurK9z27NmzYX1iYiKsR89b6vdKPfaFqOHDeDObJelfJT0gaY2kLWa2plkDA9BcVV6zr5d00N0PufuYpOckbWrOsAA0W5WwL5X02ynfDxe3/R4z6zGzPjPrq/BYACqq8pp9uhc9X3kB5+69knol3qAD6lRlzz4s6fop318n6XC14QBolSphf1PSSjO7wcy6JH1H0svNGRaAZmv4MN7dz5nZo5J+qcnW29PuPtC0kV1E5s2bF9Y///zzsH7u3LlK9UhqbHPnzg3rqbbhyZMnS2uptmCqZdnd3R3Wo/bZ2NhYuG3KnDlzGn7sulTqs7v7bkm7mzQWAC3E6bJAJgg7kAnCDmSCsAOZIOxAJgg7kAlr57xdTpedXqqfnOqFR06fPh3WU9NEq1q4cGFpbXR0tNJ9p3rd0fkHqb/71L9JavtWP6+Rsvns7NmBTBB2IBOEHcgEYQcyQdiBTBB2IBNtvZQ0ppe6ymqqjRNNFU21iC65JP7/PtXeSrUFq7TXUlfVTU3tjX731O+VmtobTd3tVOzZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IBFNc2yA1XTLVZ09NU63y2Kl61UsuV5F6XlJjj84/SJ27kDr/IPXYdV5KmimuQOYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgvnsbZBa1jjV0zWbtm36O1XmbS9YsCCsp3rdixYtCuu33XZbaW3fvn3htv39/WE9dQ5A9Lul5qOn+vCp57UTVQq7mX0oaVTSuKRz7n57MwYFoPmasWe/192PNeF+ALQQr9mBTFQNu0v6lZntNbOe6X7AzHrMrM/M+io+FoAKqh7Gb3D3w2a2WNIeMzvg7q9O/QF375XUK+U7EQboBJX27O5+uPh8VNJLktY3Y1AAmq/hsJtZt5ktPP+1pG9J2t+sgQForiqH8ddIeqnoAc+W9B/u/oumjOoik+qTp/rsVZYXjvrcM6kvW7YsrC9fvjysL168uLT2xhtvhNumeuFDQ0NhPTq/4dJLLw23PXXqVFhPXbO+EzUcdnc/JOnWJo4FQAvRegMyQdiBTBB2IBOEHcgEYQcywRTXNki1zqosayxJN998c2lt27Zt4bbr1q0L6x999FGlejQF9s477wy3ff/998P6oUOHwnp0Ce758+eH216M2LMDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJ+uxtUHX539WrV4f1TZs2ldaq9tGfeuqpsD44OBjWH3jggdLa5s2bw203btwY1l977bWwHk2BTS2DnbpU9Lx588J61XMnWoE9O5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmaDP3gFS8923bt0a1rds2VJa27NnT7jtCy+8ENZTffTh4eGwHvXxr7zyynDbVK87tZx0dLnoVJ89dW5EJ/bRU9izA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCfrsbbBgwYKwPnfu3LB+yy23hPWrr766tPb666+H2+7evTusp3rdqeWoV6xYUVpbtWpVuG1qSedPP/00rEe99NS5DWfOnAnrF6Lknt3Mnjazo2a2f8pti8xsj5kNFZ+vaO0wAVQ1k8P47ZLu/9Jtj0t6xd1XSnql+B5AB0uG3d1flfTZl27eJGlH8fUOSZubOywAzdboa/Zr3P2IJLn7ETNbXPaDZtYjqafBxwHQJC1/g87deyX1SpKZxe+KAGiZRltvI2a2RJKKz0ebNyQArdBo2F+WdH7e5VZJP2/OcAC0SvIw3syelXSPpKvMbFjSDyU9Kel5M3tE0keSvt3KQV7oxsbGwvq9994b1lN9+uj66QcPHgy3nZiYCOvj4+NhPeqjS9KNN95YWkvNGR8YGAjrhw8fDuuRVJ89JZorL0mnTp2qdP+tkAy7u5ddGeGbTR4LgBbidFkgE4QdyARhBzJB2IFMEHYgE0xxbYMvvvgirN93331hfc2aNWE9uhx0ahpoyrlz58L6yZMnw/qhQ4dKa/39/eG277zzTlhPtc+6u7tLa6kprKnfu2rrrg7s2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyAR99jZITVFdvnx5WE9dzvmDDz4orUVLJkvpaaapfvLx48fD+rFjx0prBw4cCLeNfq+ZqHI56NRznpq23InYswOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAn67G2wYcOGsH755ZeH9cHBwbC+d+/e0tqJEyfCbWfNmhXWFy8uXdlLknTrrbeG9bvuuqu0Njo6Gm47NDQU1lNSc9Ij8+fPD+vRctCdij07kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZoM/eBitXrgzrS5YsCeupZZc//vjj0trs2fE/caoXvXDhwrC+bdu2sL527drS2vPPPx9uOzIyEtZTyyZHv3vq/IML8brwKck9u5k9bWZHzWz/lNueMLOPzay/+HiwtcMEUNVMDuO3S7p/mtv/2d3XFh+7mzssAM2WDLu7vyrpszaMBUALVXmD7lEz21cc5l9R9kNm1mNmfWbWV+GxAFTUaNh/LOkbktZKOiLpR2U/6O697n67u9/e4GMBaIKGwu7uI+4+7u4Tkn4iaX1zhwWg2RoKu5lN7RU9JGl/2c8C6AzJPruZPSvpHklXmdmwpB9KusfM1kpySR9K+m7rhnjhi9YJl6Surq6w/vbbb4f14eHh0lqqjz537tywfscdd4T1a6+9NqxH/ey+vvhtHDML66l176PtU/P4L8Y+ezLs7r5lmpt/2oKxAGghTpcFMkHYgUwQdiAThB3IBGEHMsEU1zbYtWtXWL/77rvD+rp168L6ww8/XFrbvz8+BSJ1qejNmzeH9WXLloX1Z555prT23nvvhdum2l9VlptO3ffF2Hpjzw5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCasnf1EM7v4mpczcN1114X19evja3/ccMMNYX3FihWltaVLl4bb3nTTTWF93rx5YX3nzp1hffv27aW1gYGBcNvx8fGwnpqeOzY2VlpL/d3PmTMnrKemDtfZp3f3aef2smcHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT9NnbYP78+WH99OnTYT3VK3/ooYdKa6tWrQq3TY3tk08+CevPPfdcWD9w4EBpLdWrTl1KOnUOQOp5jaQuNT0xMRHW6bMDqA1hBzJB2IFMEHYgE4QdyARhBzJB2IFM0Gdvg1Q/OLX0cKrnu3r16tJaqh88MjIS1lO97tSc8+PHj4f1SGpOecrZs2cb3jb1nKeknpdWarjPbmbXm9mvzWzQzAbM7PvF7YvMbI+ZDRWfr2j2oAE0z0wO489J+kt3/0NJfyzpe2a2RtLjkl5x95WSXim+B9ChkmF39yPu/lbx9aikQUlLJW2StKP4sR2SNrdojACa4Gut9WZmKyStk/QbSde4+xFp8j8EM5t20TAz65HUU3GcACqacdjNbIGknZIec/cTqTduznP3Xkm9xX1k+QYd0Alm1HozszmaDPrP3P3F4uYRM1tS1JdIOtqaIQJohmTrzSZ34Tskfebuj025/R8k/Z+7P2lmj0ta5O5/lbivLPfsl112WVhPTfU8depUWI+WLu7u7g63TU0DTY2tq6ur4e2rLLkstba9lWq9perRZaxbraz1NpPD+A2S/kzSu2bWX9z2A0lPSnrezB6R9JGkbzdhnABaJBl2d39NUtkL9G82dzgAWoXTZYFMEHYgE4QdyARhBzJB2IFMMMW1A6T6zal61MuePTtuuKTuO9UvTp1JGf19pcaW6vGnzPQsz+mkcpE6v6AT++zs2YFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyMTXuiwVGpNaFjk1LzvVL4760VXno6dU6bPP4FoKlerRpahTl5lOjS11ie5OxJ4dyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMMJ8duMgwnx3IHGEHMkHYgUwQdiAThB3IBGEHMkHYgUwkw25m15vZr81s0MwGzOz7xe1PmNnHZtZffDzY+uECaFTypBozWyJpibu/ZWYLJe2VtFnSn0o66e7/OOMH46QaoOXKTqqZyfrsRyQdKb4eNbNBSUubOzwArfa1XrOb2QpJ6yT9prjpUTPbZ2ZPm9kVJdv0mFmfmfVVGyqAKmZ8bryZLZD0n5L+zt1fNLNrJB2T5JL+VpOH+n+RuA8O44EWKzuMn1HYzWyOpF2Sfunu/zRNfYWkXe5+c+J+CDvQYg1PhLHJS3j+VNLg1KAXb9yd95Ck/VUHCaB1ZvJu/EZJ/yXpXUnnr5/7A0lbJK3V5GH8h5K+W7yZF90Xe3agxSodxjcLYQdaj/nsQOYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmSDsQCYIO5CJ5AUnm+yYpP+d8v1VxW2dqFPH1qnjkhhbo5o5tuVlhbbOZ//Kg5v1ufvttQ0g0Klj69RxSYytUe0aG4fxQCYIO5CJusPeW/PjRzp1bJ06LomxNaotY6v1NTuA9ql7zw6gTQg7kIlawm5m95vZ/5jZQTN7vI4xlDGzD83s3WIZ6lrXpyvW0DtqZvun3LbIzPaY2VDxedo19moaW0cs4x0sM17rc1f38udtf81uZrMkvSfpTyQNS3pT0hZ3/++2DqSEmX0o6XZ3r/0EDDO7W9JJSc+cX1rLzP5e0mfu/mTxH+UV7v7XHTK2J/Q1l/Fu0djKlhn/c9X43DVz+fNG1LFnXy/poLsfcvcxSc9J2lTDODqeu78q6bMv3bxJ0o7i6x2a/GNpu5KxdQR3P+LubxVfj0o6v8x4rc9dMK62qCPsSyX9dsr3w+qs9d5d0q/MbK+Z9dQ9mGlcc36ZreLz4prH82XJZbzb6UvLjHfMc9fI8udV1RH26Zam6aT+3wZ3/yNJD0j6XnG4ipn5saRvaHINwCOSflTnYIplxndKeszdT9Q5lqmmGVdbnrc6wj4s6fop318n6XAN45iWux8uPh+V9JImX3Z0kpHzK+gWn4/WPJ7fcfcRdx939wlJP1GNz12xzPhOST9z9xeLm2t/7qYbV7uetzrC/qaklWZ2g5l1SfqOpJdrGMdXmFl38caJzKxb0rfUeUtRvyxpa/H1Vkk/r3Esv6dTlvEuW2ZcNT93tS9/7u5t/5D0oCbfkX9f0t/UMYaScf2BpHeKj4G6xybpWU0e1p3V5BHRI5KulPSKpKHi86IOGtu/a3Jp732aDNaSmsa2UZMvDfdJ6i8+Hqz7uQvG1ZbnjdNlgUxwBh2QCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5n4f8P7jep6GQ95AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(image, label, dataset):\n",
    "    print(f\"Label: {label}\") \n",
    "    plt.imshow(image.permute(1,2,0))\n",
    "    plt.show()\n",
    "\n",
    "show_image(*train_dataset[10], train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.091045Z",
     "start_time": "2021-03-21T13:02:43.088217Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path, epoch, model_name):\n",
    "    \"\"\"\n",
    "    state: checkpoint to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    #print(f_path)\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, model_name + \"_epoch_\" + str(epoch) + \"_model.pt\")\n",
    "    \n",
    "    # if it is a best model, min validation loss\n",
    "    #if is_best:\n",
    "    #    best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "    #    shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.095007Z",
     "start_time": "2021-03-21T13:02:43.092958Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_checkpoints/resnet/\"\n",
    "best_model_path = \"./Users/tobiasschulz/Documents/GitHub/digit_dataset/Classifier/saved_best_model/resnet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.173687Z",
     "start_time": "2021-03-21T13:02:43.096608Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(start_epochs, n_epochs, valid_loss_min_input, checkpoint_path, best_model_path, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Keyword arguments:\n",
    "    start_epochs -- the real part (default 0.0)\n",
    "    n_epochs -- the imaginary part (default 0.0)\n",
    "    valid_loss_min_input\n",
    "    loaders\n",
    "    model\n",
    "    optimizer\n",
    "    criterion\n",
    "    use_cuda\n",
    "    checkpoint_path\n",
    "    best_model_path\n",
    "    \n",
    "    returns trained model\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = valid_loss_min_input \n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    train_losses, valid_losses = [], []\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    print(model_name)\n",
    "    \n",
    "    for epoch in range(start_epochs, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            # move to GPU\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, targets)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            ## record the average training loss, using something like\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (x, y) in enumerate(test_loader):\n",
    "            # move to GPU\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            ## update the average validation loss\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model.forward(x)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, y)\n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "            _, predictions = output.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(test_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "              \n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "    \n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path, epoch+1, model_name)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
    "    \n",
    "    documentation[model_name] = float(num_correct)/float(num_samples)*100\n",
    "    \n",
    "    # return trained model\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.183733Z",
     "start_time": "2021-03-21T13:02:43.177735Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN_own(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_own, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.190848Z",
     "start_time": "2021-03-21T13:02:43.186719Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN_own()\n",
    "model_name = model.__class__.__name__\n",
    "documentation = {model_name: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.195448Z",
     "start_time": "2021-03-21T13:02:43.192754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.NLLLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.236777Z",
     "start_time": "2021-03-21T13:02:43.197731Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_own\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-44df326748ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CNN OWN training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-6696d36810a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(start_epochs, n_epochs, valid_loss_min_input, checkpoint_path, best_model_path, criterion, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-488f7a8cddb0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "# CNN OWN training\n",
    "trained_model = train(0, 20, 0.005, checkpoint_path, best_model_path, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.238288Z",
     "start_time": "2021-03-21T13:02:42.945Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.239426Z",
     "start_time": "2021-03-21T13:02:42.946Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"documentation.json\", \"w\") as outfile: \n",
    "    json.dump(documentation, outfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with CNN_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.240382Z",
     "start_time": "2021-03-21T13:02:42.948Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.241690Z",
     "start_time": "2021-03-21T13:02:42.949Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_dataset = ImageFolder(root = './dataset_images_keras/test/',\n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.242736Z",
     "start_time": "2021-03-21T13:02:42.949Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.243665Z",
     "start_time": "2021-03-21T13:02:42.950Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.244553Z",
     "start_time": "2021-03-21T13:02:42.951Z"
    }
   },
   "outputs": [],
   "source": [
    "img67 = cv2.imread(\"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/67.png\")\n",
    "plt.imshow(img67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.245582Z",
     "start_time": "2021-03-21T13:02:42.952Z"
    }
   },
   "outputs": [],
   "source": [
    "label = predict_image(img67)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.246483Z",
     "start_time": "2021-03-21T13:02:42.953Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Users/tobiasschulz/Documents/GitHub/ai-fall-exercises/M6/07. Template matching, corners and Haar cascades/img/export/\"\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "images = [ x for x in images if \".DS_Store\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.247404Z",
     "start_time": "2021-03-21T13:02:42.954Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for image in images:\n",
    "    image_name = image.split(\"/\")[-1:][0].split('.')[0]\n",
    "    img = cv2.imread(image)\n",
    "    label = predict_image(img)\n",
    "    predictions[image_name] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:43.248367Z",
     "start_time": "2021-03-21T13:02:42.955Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-21T13:02:17.699708Z",
     "start_time": "2021-03-21T13:01:55.791Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"sample_file.json\", \"r+\") as file:\n",
    "    data = json.load(file)\n",
    "    data.update(documentation)\n",
    "    file.seek(0)\n",
    "    json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
